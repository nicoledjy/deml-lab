{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task1-todo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjohGLavRa52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eeed6c2f-7568-47cd-c1f0-76cb3c57d882"
      },
      "source": [
        "!pip install tensorflow-data-validation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-data-validation\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/86/77ec6a7c5c91ac69798fc3a9c911ff225a4c2833a42fb59d63c8162679e7/tensorflow_data_validation-0.14.1-cp36-cp36m-manylinux2010_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata<0.15,>=0.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (0.14.0)\n",
            "Collecting scikit-learn<0.21,>=0.18 (from tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/5b/5da31a6572dc6b7b2846a7cfcbe2e060a0e6af0e1059a6516965e40371b7/scikit_learn-0.20.4-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib<1,>=0.12 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (0.14.0)\n",
            "Collecting apache-beam[gcp]<3,>=2.14 (from tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/b3/b6dcbd94bf8a5ae6a0be5fc988bdfb0b0dfb87ea37e788dc4dcc039a3aee/apache_beam-2.16.0-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py<1,>=0.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (0.8.0)\n",
            "Requirement already satisfied: pyarrow<0.15.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (0.14.1)\n",
            "Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (1.16.5)\n",
            "Requirement already satisfied: IPython>=5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (5.5.0)\n",
            "Requirement already satisfied: pandas<1,>=0.24 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (0.24.2)\n",
            "Collecting tensorflow-transform<0.15,>=0.14 (from tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/84/c8770b330a3fbe4e6a727e3e922a04d3a755a79870e4ee090b959cb01983/tensorflow-transform-0.14.0.tar.gz (221kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-data-validation) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf<4,>=3.7->tensorflow-data-validation) (41.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata<0.15,>=0.14->tensorflow-data-validation) (1.6.0)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.21,>=0.18->tensorflow-data-validation) (1.3.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.7)\n",
            "Collecting fastavro<0.22,>=0.21.4 (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/28/0206330c0002b1e28e21473117d0dc813defbd5891562d27af5c68c93899/fastavro-0.21.24-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 24.1MB/s \n",
            "\u001b[?25hCollecting python-dateutil<3,>=2.8.0 (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml<4.0.0,>=3.12 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (3.13)\n",
            "Collecting avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "  Downloading https://files.pythonhosted.org/packages/76/b2/98a736a31213d3e281a62bcae5572cf297d2546bc429accf36f9ee1604bf/avro-python3-1.9.1.tar.gz\n",
            "Requirement already satisfied: grpcio<2,>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.15.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.3.0)\n",
            "Collecting mock<3.0.0,>=1.0.1 (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 21.7MB/s \n",
            "\u001b[?25hCollecting dill<0.3.1,>=0.3.0 (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/7a/70803635c850e351257029089d38748516a280864c97cbc73087afef6d51/dill-0.3.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2<=0.12.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (0.11.3)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (2018.9)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (3.9.0)\n",
            "Requirement already satisfied: future<1.0.0,>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (0.16.0)\n",
            "Collecting oauth2client<4,>=2.0.1 (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/7b/bc893e35d6ca46a72faa4b9eaac25c687ce60e1fbe978993fe2de1b0ff0d/oauth2client-3.0.0.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 26.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.0.3)\n",
            "Requirement already satisfied: google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.14.1)\n",
            "Requirement already satisfied: cachetools<4,>=3.1.0; extra == \"gcp\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (3.1.1)\n",
            "Collecting google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\" (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/af/0ef7d097a1d5ad0c843867600e86de915e8ab8864740f49a4636cfb51af6/google_cloud_bigtable-1.0.0-py2.py3-none-any.whl (232kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 40.8MB/s \n",
            "\u001b[?25hCollecting google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\" (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/91/07a82945a7396ea34debafd476724bb5fc267c292790fdf2138c693f95c5/google_cloud_pubsub-1.0.2-py2.py3-none-any.whl (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 42.4MB/s \n",
            "\u001b[?25hCollecting google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/32/df3e36fd705a00092f1ffa9f41ce1df8dcb594ae313d239b87861a41fc2e/google-apitools-0.5.28.tar.gz (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 40.9MB/s \n",
            "\u001b[?25hCollecting google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" (from apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/aa/29cbcf8cf7d08ce2d55b9dce858f7c632b434cb6451bed17cb4275804217/google_cloud_datastore-1.7.4-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 26.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython>=5.0->tensorflow-data-validation) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython>=5.0->tensorflow-data-validation) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython>=5.0->tensorflow-data-validation) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython>=5.0->tensorflow-data-validation) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython>=5.0->tensorflow-data-validation) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython>=5.0->tensorflow-data-validation) (4.4.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython>=5.0->tensorflow-data-validation) (4.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot<2,>=1.2.0->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (2.4.2)\n",
            "Collecting pbr>=0.11 (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/a4/d5c83831a3452713e4b4f126149bc4fbda170f7cb16a86a00ce57ce0e9ad/pbr-5.4.3-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (0.6.2)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (2.21.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (0.4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (0.2.6)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (4.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2,>=0.28.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.14.2)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (0.4.1)\n",
            "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3 (from google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "  Downloading https://files.pythonhosted.org/packages/65/19/2060c8faa325fddc09aa67af98ffcb6813f39a0ad805679fa64815362b3a/grpc-google-iam-v1-0.12.3.tar.gz\n",
            "Collecting fasteners>=0.14 (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "  Downloading https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython>=5.0->tensorflow-data-validation) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=5.0->tensorflow-data-validation) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython>=5.0->tensorflow-data-validation) (0.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (2019.9.11)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2,>=0.28.1; extra == \"gcp\"->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation) (1.4.2)\n",
            "Collecting monotonic>=0.1 (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.14->tensorflow-data-validation)\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: tensorflow-transform, avro-python3, dill, hdfs, oauth2client, google-apitools, grpc-google-iam-v1\n",
            "  Building wheel for tensorflow-transform (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-transform: filename=tensorflow_transform-0.14.0-cp36-none-any.whl size=282799 sha256=51a968469220da212e5a1eb8d5523a2eef3a9a80c8ba40eb88337570534195cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/8f/19/808f4a2d4d23a13b6ec44682fc2662646e8d9193b49f4a5f93\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.1-cp36-none-any.whl size=43199 sha256=1f461c49c2a73e2cfab6af15002f41296c5e91fff525e3fbe6c28266436c21ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/54/6f/a5df680fd3224aa45145686f3b1b02a878a90ea769fcf9daaf\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.0-cp36-none-any.whl size=77513 sha256=180ada4af268647d76bfb03ddf19126f8999902507dc7a59ded7694de2d0e8fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/de/a4/a91eec4eea652104d8c81b633f32ead5eb57d1b294eab24167\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.5.8-cp36-none-any.whl size=33214 sha256=bd7b69e3498144b01f4006fb6e0199bb972a3f354697017ea9f3f6bff7e115d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oauth2client: filename=oauth2client-3.0.0-cp36-none-any.whl size=106382 sha256=daedc16037077c688db960ea6e2198b052be49371e3aa77ba902b8088a200c7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.28-cp36-none-any.whl size=130111 sha256=2da65488dcdc7d346c3ae22e1e578c87c16eb8ac1ef7599d21805292bcdaed20\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/c2/92/837e8a4d649a209dff85b38d7fbb576b4b480738be70865f29\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpc-google-iam-v1: filename=grpc_google_iam_v1-0.12.3-cp36-none-any.whl size=18499 sha256=68539b855da1492a2ed34aaee30e8d59316a6a46de49d03245c3c5bd269cac3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/3a/83/77a1e18e1a8757186df834b86ce6800120ac9c79cd8ca4091b\n",
            "Successfully built tensorflow-transform avro-python3 dill hdfs oauth2client google-apitools grpc-google-iam-v1\n",
            "\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.9 has requirement dill>=0.3.1, but you'll have dill 0.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-learn, fastavro, python-dateutil, avro-python3, pbr, mock, dill, hdfs, oauth2client, grpc-google-iam-v1, google-cloud-bigtable, google-cloud-pubsub, monotonic, fasteners, google-apitools, google-cloud-datastore, apache-beam, tensorflow-transform, tensorflow-data-validation\n",
            "  Found existing installation: scikit-learn 0.21.3\n",
            "    Uninstalling scikit-learn-0.21.3:\n",
            "      Successfully uninstalled scikit-learn-0.21.3\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "  Found existing installation: dill 0.3.1.1\n",
            "    Uninstalling dill-0.3.1.1:\n",
            "      Successfully uninstalled dill-0.3.1.1\n",
            "  Found existing installation: oauth2client 4.1.3\n",
            "    Uninstalling oauth2client-4.1.3:\n",
            "      Successfully uninstalled oauth2client-4.1.3\n",
            "  Found existing installation: google-cloud-datastore 1.8.0\n",
            "    Uninstalling google-cloud-datastore-1.8.0:\n",
            "      Successfully uninstalled google-cloud-datastore-1.8.0\n",
            "Successfully installed apache-beam-2.16.0 avro-python3-1.9.1 dill-0.3.0 fastavro-0.21.24 fasteners-0.15 google-apitools-0.5.28 google-cloud-bigtable-1.0.0 google-cloud-datastore-1.7.4 google-cloud-pubsub-1.0.2 grpc-google-iam-v1-0.12.3 hdfs-2.5.8 mock-2.0.0 monotonic-1.5 oauth2client-3.0.0 pbr-5.4.3 python-dateutil-2.8.0 scikit-learn-0.20.4 tensorflow-data-validation-0.14.1 tensorflow-transform-0.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKqIguOHKpYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "import tensorflow_data_validation as tfdv\n",
        "\n",
        "CSV_DELIMITER = '\\t'\n",
        "\n",
        "\n",
        "def infer_schema_from_csv(csv_file, column_names):\n",
        "    pass\n",
        "\n",
        "\n",
        "def has_anomalies(csv_file, schema):\n",
        "    pass\n",
        "\n",
        "  \n",
        "def adjust_product_schema(schema):\n",
        "    pass\n",
        "\n",
        "def adjust_rating_schema(schema):\n",
        "    pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WJHlxiSSNn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "\n",
        "temp = tempfile.gettempdir()\n",
        "zip, headers = urllib.request.urlretrieve('https://raw.githubusercontent.com/schelterlabs/deml-lab/master/assignment2/data.zip')\n",
        "zipfile.ZipFile(zip).extractall(temp)\n",
        "zipfile.ZipFile(zip).close()\n",
        "urllib.request.urlcleanup()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkB0RH5ISqna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def path_to_file(file):\n",
        "  return os.path.join(temp, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwbjhp8RKX8m",
        "colab_type": "code",
        "outputId": "fc62ba7e-be95-4b64-8163-7d76aee205e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "# We infer the schema from the first data file\n",
        "#product_schema = infer_schema_from_csv('data/products-data-0.tsv', column_names=['id', 'category', 'description'])\n",
        "product_schema = infer_schema_from_csv(path_to_file('data/products-data-0.tsv'), column_names=['id', 'category', 'description'])\n",
        "\n",
        "# We adjust the schema with some constraint that the automatic inference might not have captured\n",
        "adjust_product_schema(product_schema)\n",
        "\n",
        "# We use the schema to check for anomalies in subsequent data files\n",
        "assert not has_anomalies(path_to_file('data/products-data-0.tsv'), product_schema)\n",
        "assert not has_anomalies(path_to_file('data/products-data-1.tsv'), product_schema)\n",
        "assert not has_anomalies(path_to_file('data/products-data-2.tsv'), product_schema)\n",
        "assert has_anomalies(path_to_file('data/products-data-3.tsv'), product_schema)\n",
        "\n",
        "# We infer the schema from the first data file\n",
        "rating_schema = infer_schema_from_csv(path_to_file('data/ratings-0.tsv'), column_names=['id', 'rating'])\n",
        "\n",
        "# We adjust the schema with some constraint that the automatic inference might not have captured\n",
        "adjust_rating_schema(rating_schema)\n",
        "\n",
        "# We use the schema to check for anomalies in subsequent data files\n",
        "assert not has_anomalies(path_to_file('data/ratings-0.tsv'), rating_schema)\n",
        "assert not has_anomalies(path_to_file('data/ratings-1.tsv'), rating_schema)\n",
        "assert has_anomalies(path_to_file('data/ratings-2.tsv'), rating_schema)\n",
        "assert has_anomalies(path_to_file('data/ratings-3.tsv'), rating_schema)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b6bf5386160e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_anomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/products-data-1.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_anomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/products-data-2.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mhas_anomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/products-data-3.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# We infer the schema from the first data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
